# Phase 2 (Glyph Classification) Configuration
# Updated: Increased CNN capacity, adjusted embedding size, switched scheduler to cosine with warmup,
# earlier unweighting, tuned class weight alpha, and added classifier MLP head.
# Added commented inference script (bottom) mapping labels to base_unicode via data/chars.csv.
#
# Purpose: Classify full glyphs from their 16x16 grid of primitive IDs (0..1023).

experiment:
  name: phase2_cnn_capacity_v2
  notes: >
    Higher-capacity CNN (stages [96,192,256], blocks [3,3,3], embedding_dim=96, classifier_hidden=256),
    cosine LR schedule (warmup=3, min_lr_scale=0.05), earlier unweighting (epoch 12).

seed: 42
deterministic: true

# ------------------------------------------------------------------
# Data Paths
# ------------------------------------------------------------------
data:
  root: data/grids_memmap
  grids_dir: data/grids_memmap
  labels_file: data/grids_memmap/label_map.json
  index_train: data/grids_memmap/splits/phase2_train_ids.txt
  index_val: data/grids_memmap/splits/phase2_val_ids.txt
  index_test: data/grids_memmap/splits/phase2_test_ids.txt
  primitive_centroids: assets/centroids/primitive_centroids.npy
  memmap_grids_file: data/grids_memmap/grids_uint16.npy
  memmap_row_ids_file: data/grids_memmap/glyph_row_ids.npy
  glyph_labels_file: data/grids_memmap/glyph_labels.jsonl

# ------------------------------------------------------------------
# Input Representation
# ------------------------------------------------------------------
input:
  grid_rows: 16
  grid_cols: 16
  primitive_vocab_size: 1024
  embedding_dim: 96
  positional_encoding: sinusoidal_2d
  combine_mode: add
  patch_grouping:
    enabled: true
    patch_rows: 4
    patch_cols: 4
  token_pooling: cls
  use_cls_token: true
  normalize_embeddings: false

# ------------------------------------------------------------------
# Model Definition
# ------------------------------------------------------------------
model:
  architecture: cnn
  transformer: # kept for easy switch; unused when architecture=cnn
    num_layers: 5
    d_model: 256
    num_heads: 8
    mlp_hidden_dim: 512
    dropout: 0.1
    attention_dropout: 0.1
    layer_norm_eps: 1.0e-5
    pre_norm: true
  classifier:
    hidden_dim: 256
    dropout: 0.1
    activation: gelu
  cnn:
    stages: [96, 192, 256]
    blocks_per_stage: [3, 3, 3]
    kernel_size: 3
    stem_kernel_size: 3
    stem_stride: 1
    downsample: conv
    activation: gelu
    dropout: 0.15
    classifier_hidden_dim: 256
    classifier_dropout: 0.30
  init:
    embedding_from_centroids: false
    centroid_requires_grad: true
    cls_init: normal
    weight_init: xavier_uniform

# ------------------------------------------------------------------
# Optimization & Training
# ------------------------------------------------------------------
optim:
  name: adamw
  lr: 0.0005
  weight_decay: 1.0e-4
  betas: [0.9, 0.999]
  eps: 1.0e-8
  grad_clip_norm: 1.0

scheduler:
  strategy: cosine
  warmup_epochs: 3
  min_lr_scale: 0.05

training:
  unweighted_finetune_after_epoch: 12
  epochs: 40
  batch_size: 1024
  eval_batch_size: 1024
  num_workers: 2
  pin_memory: true
  gradient_accumulation_steps: 1
  auto_lr_scale: true
  base_batch_size_for_lr: 256
  target_effective_batch_size: 4096
  compile: true
  log_interval_steps: 25
  token_id_dropout: 0.02
  val_interval_epochs: 1
  save_every_epochs: 1
  mixed_precision: amp
  cache_grids: true
  resume_from:

early_stopping:
  enabled: true
  metric: val/accuracy_top1
  mode: max
  patience: 6
  min_delta: 0.0005

# ------------------------------------------------------------------
# Loss Configuration
# ------------------------------------------------------------------
loss:
  primary: cross_entropy
  label_smoothing: 0.05
  class_weights: auto_inverse_freq
  class_weights_alpha: 0.2
  auxiliary_diacritic:
    enabled: false
    weight: 0.1
    label_source: metadata
  reduction: mean

# ------------------------------------------------------------------
# Metrics
# ------------------------------------------------------------------
metrics:
  - accuracy_top1
  - accuracy_top5
  - macro_f1
  - per_class_accuracy
  - diacritic_subset_accuracy
  - ligature_subset_accuracy

# ------------------------------------------------------------------
# Checkpointing
# ------------------------------------------------------------------
checkpoint:
  dir: checkpoints/phase2
  monitor: val/accuracy_top1
  mode: max
  save_top_k: 3
  save_last: true
  filename_pattern: "epoch{epoch:02d}-val{val_accuracy_top1:.4f}.pt"
  keep_every_n_epochs: 0

# ------------------------------------------------------------------
# Logging
# ------------------------------------------------------------------
logging:
  backend: tensorboard
  tensorboard_dir: logs/phase2
  run_name: "${experiment.name}"
  log_hparams: true
  wandb:
    enabled: false
    project: glyph-grid
    tags: ["phase2", "cnn", "capacity"]

# ------------------------------------------------------------------
# Evaluation / Analysis Hooks
# ------------------------------------------------------------------
evaluation:
  confusion_matrix: true
  topk: [1, 5]
  attention_heatmap:
    enabled: true
    sample_count: 50
  export_embeddings:
    enabled: false
    layer: penultimate
    path: artifacts/phase2_glyph_embeddings.npy

# ------------------------------------------------------------------
# Sanity & Validation
# ------------------------------------------------------------------
sanity:
  expect_grid_shape: [16, 16]
  primitive_vocab_size: 1024
  embedding_dim: 96
  d_model: 256
  mlp_hidden_dim: 512
  assert_cls_token: true

# ------------------------------------------------------------------
# Debug
# ------------------------------------------------------------------
debug:
  fast_dev_run: false
  limit_train_batches: null
  limit_val_batches: null
  overfit_batches: 0
  deterministic_hash_check: false
# ------------------------------------------------------------------
# Notes
# ------------------------------------------------------------------
# Capacity changes: embedding_dimâ†’96, CNN widened/deepened.
# Earlier unweighted fine-tune to rebalance head classes.
# Cosine schedule for smoother late convergence.

# ------------------------------------------------------------------
# Inference Script (Commented)
# ------------------------------------------------------------------
# Save the following as scripts/infer_chain.py (example). It maps predicted label -> base_unicode using data/chars.csv.
# Usage:
#   python scripts/infer_chain.py --rasters_dir data/rasters --phase1_ckpt checkpoints/phase1/best.pt \
#       --phase2_ckpt checkpoints/phase2/best.pt --label_map data/grids_memmap/label_map.json --chars_csv data/chars.csv --arch cnn --limit 5
#
# ---------------------------------------------------------------
# import argparse, json, csv
# from pathlib import Path
# import torch, numpy as np
# from PIL import Image
# from models.phase1_cnn import build_phase1_model
# from models.phase2_cnn import build_phase2_cnn_model
# from models.phase2_transformer import build_phase2_model
#
# DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
#
# def load_label_map(path: Path):
#     lm = json.loads(path.read_text(encoding="utf-8"))
#     inv = [None] * len(lm)
#     for k,v in lm.items():
#         inv[v] = k
#     return lm, inv
#
# def load_chars_csv(chars_csv: Path):
#     # Build mapping label -> base_unicode (first occurrence kept)
#     mapping = {}
#     with chars_csv.open("r", encoding="utf-8") as f:
#         reader = csv.DictReader(f)
#         for row in reader:
#             lbl = row["label"]
#             base = row["base_unicode"]
#             mapping.setdefault(lbl, base)
#     return mapping
#
# def load_phase1(ckpt: Path):
#     cfg = {
#         "in_channels": 1,
#         "conv_blocks": [
#             {"out_channels":32,"kernel":3,"stride":1,"padding":1,"batchnorm":True,"pool":2},
#             {"out_channels":64,"kernel":3,"stride":1,"padding":1,"batchnorm":True,"pool":2},
#         ],
#         "flatten_dim":256,"fc_hidden":128,"fc_dropout":0.2,"num_classes":1024,"weight_init":"kaiming_normal"
#     }
#     m = build_phase1_model(cfg)
#     payload = torch.load(str(ckpt), map_location="cpu")
#     state = payload.get("model_state") or payload
#     m.load_state_dict(state, strict=False)
#     return m.to(DEVICE).eval()
#
# def build_phase2(ckpt: Path, num_labels: int, arch: str):
#     payload = torch.load(str(ckpt), map_location="cpu")
#     cfg_root = payload.get("config", {}) or {}
#     if arch == "cnn":
#         cnn_cfg = cfg_root if cfg_root else {
#             "input":{"primitive_vocab_size":1024,"embedding_dim":96,"normalize_embeddings":False},
#             "model":{"architecture":"cnn","cnn":{"stages":[96,192,256],"blocks_per_stage":[3,3,3],"kernel_size":3,
#                      "stem_kernel_size":3,"stem_stride":1,"downsample":"conv","activation":"gelu","dropout":0.15,
#                      "classifier_hidden_dim":256,"classifier_dropout":0.30},
#                      "init":{"embedding_from_centroids":False,"centroid_requires_grad":True,"weight_init":"xavier_uniform"}}
#         }
#         m = build_phase2_cnn_model(cnn_cfg, num_labels=num_labels, primitive_centroids=None)
#     else:
#         tf_cfg = cfg_root if cfg_root else {
#             "input":{"primitive_vocab_size":1024,"embedding_dim":64,"positional_encoding":"sinusoidal_2d","combine_mode":"add",
#                      "patch_grouping":{"enabled":True,"patch_rows":4,"patch_cols":4},"token_pooling":"cls","use_cls_token":True,
#                      "normalize_embeddings":False},
#             "model":{"architecture":"transformer","transformer":{"num_layers":5,"d_model":256,"num_heads":8,"mlp_hidden_dim":512,
#                      "dropout":0.1,"attention_dropout":0.1,"layer_norm_eps":1e-5,"pre_norm":True},
#                      "classifier":{"hidden_dim":256,"dropout":0.1,"activation":"gelu"},
#                      "init":{"embedding_from_centroids":False,"centroid_requires_grad":True,"weight_init":"xavier_uniform","cls_init":"normal"}}
#         }
#         m = build_phase2_model(tf_cfg, num_labels=num_labels, primitive_centroids=None)
#     state = payload.get("model_state") or payload
#     m.load_state_dict(state, strict=False)
#     return m.to(DEVICE).eval()
#
# def raster_to_grid(p: Path, phase1):
#     img = Image.open(p).convert("L")
#     arr = np.array(img, dtype=np.uint8)
#     if arr.shape != (128,128):
#         raise ValueError(f"Expected 128x128 raster; got {arr.shape}")
#     patches = []
#     for gy in range(16):
#         for gx in range(16):
#             cell = arr[gy*8:(gy+1)*8, gx*8:(gx+1)*8]
#             t = torch.from_numpy(cell).unsqueeze(0).unsqueeze(0)  # (1,1,8,8)
#             patches.append(t)
#     batch = torch.cat(patches, dim=0).to(DEVICE)
#     with torch.no_grad():
#         logits = phase1(batch)
#         preds = torch.argmax(logits, dim=1)
#     return preds.view(16,16).cpu()
#
# def predict_glyph(grid: torch.Tensor, phase2, topk: int):
#     g = grid.to(torch.long).unsqueeze(0).to(DEVICE)
#     with torch.no_grad():
#         logits = phase2(g)
#         probs = torch.softmax(logits, dim=1)
#         v,i = torch.topk(probs, k=topk, dim=1)
#     return i.squeeze(0).cpu(), v.squeeze(0).cpu()
#
# def main():
#     ap = argparse.ArgumentParser()
#     ap.add_argument("--rasters_dir", type=Path, required=True)
#     ap.add_argument("--phase1_ckpt", type=Path, required=True)
#     ap.add_argument("--phase2_ckpt", type=Path, required=True)
#     ap.add_argument("--label_map", type=Path, required=True)
#     ap.add_argument("--chars_csv", type=Path, required=True)
#     ap.add_argument("--arch", type=str, default="cnn", choices=["cnn","transformer"])
#     ap.add_argument("--limit", type=int, default=10)
#     ap.add_argument("--topk", type=int, default=5)
#     args = ap.parse_args()
#
#     label_map, inv_labels = load_label_map(args.label_map)
#     base_map = load_chars_csv(args.chars_csv)  # label -> base_unicode
#
#     phase1 = load_phase1(args.phase1_ckpt)
#     phase2 = build_phase2(args.phase2_ckpt, num_labels=len(label_map), arch=args.arch)
#
#     rasters = sorted(p for p in args.rasters_dir.glob("*.png"))
#     if args.limit > 0:
#         rasters = rasters[:args.limit]
#     print(f"[INFO] Inference on {len(rasters)} rasters")
#     for p in rasters:
#         grid = raster_to_grid(p, phase1)
#         idxs, probs = predict_glyph(grid, phase2, topk=args.topk)
#         labels = [inv_labels[i] for i in idxs.tolist()]
#         bases = [base_map.get(lbl, "?") for lbl in labels]
#         top1 = labels[0]
#         print(f"{p.name}: top1_label={top1} top1_base={bases[0]} prob={probs[0]:.4f} | topk={[ (l,b,round(float(pr),4)) for l,b,pr in zip(labels,bases,probs.tolist()) ]}")
#     print("[DONE]")
#
# if __name__ == "__main__":
#     main()
